{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Opacities_Seg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('MPF': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "interpreter": {
      "hash": "3dd217612e3efbc53bda62975acccf69dc94b7f474970d20d9b0bbb03e9d7037"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVjUSVTjPxMp",
        "outputId": "903808dc-6aa9-4045-a228-5c1bd460dd3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Activation, Concatenate, Dense, Reshape, BatchNormalization\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.callbacks import CSVLogger\r\n",
        "\r\n",
        "from utils.preprocess import *\r\n",
        "from utils.metrics import *"
      ],
      "outputs": [],
      "metadata": {
        "id": "94Enuf8mPfPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n"
      ],
      "metadata": {
        "id": "x76-bCZXnipQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train = np.load('X_train_Seg_op_2.npy')\r\n",
        "Y_train = np.load('Y_train_Seg_op_2.npy')\r\n",
        "X_test = np.load('X_test_Seg_op_2.npy')\r\n",
        "Y_test = np.load('Y_test_Seg_op_2.npy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "YxYnt3M_niJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "skZyNPdSpqdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train=min_max_preprocessing(X_train)\r\n",
        "X_test=min_max_preprocessing(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "nsvE4CJOp98T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train,mean,std=samplewise_preprocessing(X_train)\r\n",
        "X_test=featurewise_preprocessing(X_test,mean,std)"
      ],
      "outputs": [],
      "metadata": {
        "id": "N3MmBB00qDiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "5qPDBF2227CG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Double Unet\r\n",
        "def squeeze_excite_block(inputs, ratio=8):\r\n",
        "    init = inputs\r\n",
        "    channel_axis = -1\r\n",
        "    filters = init.shape[channel_axis]\r\n",
        "    se_shape = (1, 1, filters)\r\n",
        "\r\n",
        "    se = GlobalAveragePooling2D()(init)\r\n",
        "    se = Reshape(se_shape)(se)\r\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\r\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\r\n",
        "\r\n",
        "    x = Multiply()([init, se])\r\n",
        "    return x\r\n",
        "\r\n",
        "def conv_block(inputs, filters):\r\n",
        "    x = inputs\r\n",
        "\r\n",
        "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "\r\n",
        "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "\r\n",
        "    x = squeeze_excite_block(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "def encoder1(inputs):\r\n",
        "    skip_connections = []\r\n",
        "\r\n",
        "    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\r\n",
        "    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\r\n",
        "    for name in names:\r\n",
        "        skip_connections.append(model.get_layer(name).output)\r\n",
        "\r\n",
        "    output = model.get_layer(\"block5_conv4\").output\r\n",
        "    return output, skip_connections\r\n",
        "\r\n",
        "def decoder1(inputs, skip_connections):\r\n",
        "    num_filters = [256, 128, 64, 32]\r\n",
        "    skip_connections.reverse()\r\n",
        "    x = inputs\r\n",
        "\r\n",
        "    for i, f in enumerate(num_filters):\r\n",
        "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\r\n",
        "        x = Concatenate()([x, skip_connections[i]])\r\n",
        "        x = conv_block(x, f)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "# def encoder2(inputs):\r\n",
        "#     skip_connections = []\r\n",
        "#\r\n",
        "#     output = DenseNet121(include_top=False, weights='imagenet')(inputs)\r\n",
        "#     model = tf.keras.models.Model(inputs, output)\r\n",
        "#\r\n",
        "#     names = [\"input_2\", \"conv1/relu\", \"pool2_conv\", \"pool3_conv\"]\r\n",
        "#     for name in names:\r\n",
        "#         skip_connections.append(model.get_layer(name).output)\r\n",
        "#     output = model.get_layer(\"pool4_conv\").output\r\n",
        "#\r\n",
        "#     return output, skip_connections\r\n",
        "\r\n",
        "def encoder2(inputs):\r\n",
        "    num_filters = [32, 64, 128, 256]\r\n",
        "    skip_connections = []\r\n",
        "    x = inputs\r\n",
        "\r\n",
        "    for i, f in enumerate(num_filters):\r\n",
        "        x = conv_block(x, f)\r\n",
        "        skip_connections.append(x)\r\n",
        "        x = MaxPool2D((2, 2))(x)\r\n",
        "\r\n",
        "    return x, skip_connections\r\n",
        "\r\n",
        "def decoder2(inputs, skip_1, skip_2):\r\n",
        "    num_filters = [256, 128, 64, 32]\r\n",
        "    skip_2.reverse()\r\n",
        "    x = inputs\r\n",
        "\r\n",
        "    for i, f in enumerate(num_filters):\r\n",
        "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\r\n",
        "        x = Concatenate()([x, skip_1[i], skip_2[i]])\r\n",
        "        x = conv_block(x, f)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "def output_block(inputs):\r\n",
        "    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\r\n",
        "    x = Activation('sigmoid')(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def Upsample(tensor, size):\r\n",
        "    \"\"\"Bilinear upsampling\"\"\"\r\n",
        "    def _upsample(x, size):\r\n",
        "        return tf.image.resize(images=x, size=size)\r\n",
        "    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\r\n",
        "\r\n",
        "def ASPP(x, filter):\r\n",
        "    shape = x.shape\r\n",
        "\r\n",
        "    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\r\n",
        "    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\r\n",
        "    y1 = BatchNormalization()(y1)\r\n",
        "    y1 = Activation(\"relu\")(y1)\r\n",
        "    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\r\n",
        "\r\n",
        "    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\r\n",
        "    y2 = BatchNormalization()(y2)\r\n",
        "    y2 = Activation(\"relu\")(y2)\r\n",
        "\r\n",
        "    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\r\n",
        "    y3 = BatchNormalization()(y3)\r\n",
        "    y3 = Activation(\"relu\")(y3)\r\n",
        "\r\n",
        "    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\r\n",
        "    y4 = BatchNormalization()(y4)\r\n",
        "    y4 = Activation(\"relu\")(y4)\r\n",
        "\r\n",
        "    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\r\n",
        "    y5 = BatchNormalization()(y5)\r\n",
        "    y5 = Activation(\"relu\")(y5)\r\n",
        "\r\n",
        "    y = Concatenate()([y1, y2, y3, y4, y5])\r\n",
        "\r\n",
        "    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\r\n",
        "    y = BatchNormalization()(y)\r\n",
        "    y = Activation(\"relu\")(y)\r\n",
        "\r\n",
        "    return y\r\n",
        "\r\n",
        "def build_model(shape):\r\n",
        "    inputs = Input(shape)\r\n",
        "    x, skip_1 = encoder1(inputs)\r\n",
        "    x = ASPP(x, 64)\r\n",
        "    x = decoder1(x, skip_1)\r\n",
        "    outputs1 = output_block(x)\r\n",
        "\r\n",
        "    x = inputs * outputs1\r\n",
        "\r\n",
        "    x, skip_2 = encoder2(x)\r\n",
        "    x = ASPP(x, 64)\r\n",
        "    x = decoder2(x, skip_1, skip_2)\r\n",
        "    outputs2 = output_block(x)\r\n",
        "    #outputs = Concatenate()([outputs1, outputs2])\r\n",
        "\r\n",
        "    model = Model(inputs, outputs2)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "YNOc94_PBpYN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Unet_1():\r\n",
        "  inputs = Input(shape=(224, 224, 1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.1)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.Dropout(0.1)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.2)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "  \r\n",
        "  c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.Dropout(0.3)(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "\r\n",
        "  #Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c4])\r\n",
        "  c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c6 = tf.keras.layers.Dropout(0.2)(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  \r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c3])\r\n",
        "  c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c7 = tf.keras.layers.Dropout(0.2)(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c2])\r\n",
        "  c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c8 = tf.keras.layers.Dropout(0.1)(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  \r\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\r\n",
        "  c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\r\n",
        "  c9 = tf.keras.layers.Dropout(0.1)(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "lZXmtXtr9YOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Unet_2():\r\n",
        "  inputs = Input(shape=(224, 224, 1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.1)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(224, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.Dropout(0.1)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(224, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(448, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(448, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(448, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.2)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(448, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  \r\n",
        "\r\n",
        "  #Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(224, (2, 2), strides=(2, 2), padding='same')(c4)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c3])\r\n",
        "  c6 = tf.keras.layers.Conv2D(224, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c6 = tf.keras.layers.Dropout(0.2)(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(224, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  \r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(112, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c2])\r\n",
        "  c7 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c7 = tf.keras.layers.Dropout(0.2)(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(112, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c1])\r\n",
        "  c8 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c8 = tf.keras.layers.Dropout(0.1)(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(112, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c8)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "So8yF1HoHQo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Unet_3():\r\n",
        "  inputs = Input(shape=(224, 224, 1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.1)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.Dropout(0.1)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.2)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "  \r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.Dropout(0.3)(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "\r\n",
        "  #Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c4])\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c6 = tf.keras.layers.Dropout(0.2)(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  \r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c3])\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c7 = tf.keras.layers.Dropout(0.2)(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c2])\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c8 = tf.keras.layers.Dropout(0.1)(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  \r\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\r\n",
        "  c9 = tf.keras.layers.Dropout(0.1)(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "Su1M6WGZKIE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Vggunet():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.5)(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Dropout(0.5)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.5)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.5)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.5)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.5)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "  \r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Dropout(0.5)(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Dropout(0.5)(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p5)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Dropout(0.5)(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "\r\n",
        "  #Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c5])\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Dropout(0.5)(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "\r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c4])\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Dropout(0.5)(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c3])\r\n",
        "  c9 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Dropout(0.5)(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  \r\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c9)\r\n",
        "  u9 = tf.keras.layers.concatenate([u9, c2])\r\n",
        "  c10 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u9)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Dropout(0.5)(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  u10 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c10)\r\n",
        "  u10 = tf.keras.layers.concatenate([u10, c1])\r\n",
        "  c11 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u10)\r\n",
        "  c11 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c11)\r\n",
        "  c11 = tf.keras.layers.ReLU()(c11)\r\n",
        "  c11 = tf.keras.layers.Dropout(0.5)(c11)\r\n",
        "  c11 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c11)\r\n",
        "  c11 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c11)\r\n",
        "  c11 = tf.keras.layers.ReLU()(c11)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c11)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "EqNEEOiWJ-Av"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet1():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  u1 = tf.keras.layers.UpSampling2D(size = (2, 2))(c5)\r\n",
        "\r\n",
        "  \r\n",
        "  c6 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  u2 = tf.keras.layers.UpSampling2D(size = (2, 2))(c6)\r\n",
        "  \r\n",
        "  c7 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  u3 = tf.keras.layers.UpSampling2D(size = (2, 2))(c7)\r\n",
        "  \r\n",
        "  c8 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  u4 = tf.keras.layers.UpSampling2D(size = (2, 2))(c8)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(u4)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "0Sms0MOIyafU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet1_V2():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  u1 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\r\n",
        "\r\n",
        "  \r\n",
        "  c6 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  u2 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  \r\n",
        "  c7 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  \r\n",
        "  c8 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  u4 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(u4)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "Bn3WBoi32DQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet2():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  u1 = tf.keras.layers.UpSampling2D(size = (2, 2))(p5)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  \r\n",
        "  u2 = tf.keras.layers.UpSampling2D(size = (2, 2))(c6)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  \r\n",
        "  u3 = tf.keras.layers.UpSampling2D(size = (2, 2))(c7)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u4 = tf.keras.layers.UpSampling2D(size = (2, 2))(c8)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u4)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "\r\n",
        "  u5 = tf.keras.layers.UpSampling2D(size = (2, 2))(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u5)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "l3Hk8r-k2kTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet2_V2():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  u1 = tf.keras.layers.Conv2DTranspose(1024, (2, 2), strides=(2, 2), padding='same')(p5)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  \r\n",
        "  u2 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  \r\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u4)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "\r\n",
        "  u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u5)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "gz0V484x6XZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet3():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  u1 = tf.keras.layers.UpSampling2D(size = (2, 2))(p5)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  \r\n",
        "  u2 = tf.keras.layers.UpSampling2D(size = (2, 2))(c6)\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  \r\n",
        "  u3 = tf.keras.layers.UpSampling2D(size = (2, 2))(c7)\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u4 = tf.keras.layers.UpSampling2D(size = (2, 2))(c8)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u4)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "\r\n",
        "  u5 = tf.keras.layers.UpSampling2D(size = (2, 2))(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(u5)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "jKlNiETn4Wgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Segnet4():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  c5 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  u1 = tf.keras.layers.UpSampling2D(size = (2, 2))(p5)\r\n",
        "  c6 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(2048, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  \r\n",
        "  u2 = tf.keras.layers.UpSampling2D(size = (2, 2))(c6)\r\n",
        "  c7 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  \r\n",
        "  u3 = tf.keras.layers.UpSampling2D(size = (2, 2))(c7)\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u4 = tf.keras.layers.UpSampling2D(size = (2, 2))(c8)\r\n",
        "  c9 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u4)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "\r\n",
        "  u5 = tf.keras.layers.UpSampling2D(size = (2, 2))(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u5)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "mELZIB__CR32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Pspnet():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(2, 2))(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  cs1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  cs1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(cs1)\r\n",
        "  c1 = tf.keras.layers.Add()([c1,cs1])\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  \r\n",
        "  c2 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(c1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(2, 2))(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  cs2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  cs2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(cs2)\r\n",
        "  c2 = tf.keras.layers.Add()([c2,cs2])\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(c2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(2, 2))(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.LeakyReLU(alpha = 0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  cs3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  cs3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(cs3)\r\n",
        "  c3 = tf.keras.layers.Add()([c3,cs3])\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "\r\n",
        "  #Piramid Feature Map\r\n",
        "  r = tf.keras.layers.GlobalAveragePooling2D()(c3) \r\n",
        "  r = tf.keras.layers.Reshape((1,1,256))(r)\r\n",
        "  r = tf.keras.layers.Conv2D(64, (1, 1))(r)\r\n",
        "  r = tf.keras.layers.UpSampling2D(224,interpolation='bilinear')(r)\r\n",
        "  \r\n",
        "  y = tf.keras.layers.AveragePooling2D((2,2))(c3)\r\n",
        "  y = tf.keras.layers.Conv2D(64,(1,1))(y)\r\n",
        "  y = tf.keras.layers.UpSampling2D(2,interpolation='bilinear')(y)\r\n",
        "  \r\n",
        "  b = tf.keras.layers.AveragePooling2D((4,4))(c3)\r\n",
        "  b = tf.keras.layers.Conv2D(64,(1,1))(b)\r\n",
        "  b = tf.keras.layers.UpSampling2D(4,interpolation='bilinear')(b)\r\n",
        "    \r\n",
        "  g = tf.keras.layers.AveragePooling2D((8,8))(c3)\r\n",
        "  g = tf.keras.layers.Conv2D(64,(1,1))(g)\r\n",
        "  g = tf.keras.layers.UpSampling2D(8,interpolation='bilinear')(g)\r\n",
        "  \r\n",
        "  P = tf.keras.layers.concatenate([c3,r,y,b,g])\r\n",
        "  #P = tf.keras.layers.Add()([c3,P])\r\n",
        "\r\n",
        "  P = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(P)\r\n",
        "  P = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(P)\r\n",
        "  P = tf.keras.layers.LeakyReLU(alpha = 0.2)(P)\r\n",
        "  P = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same',dilation_rate=(1, 1))(P)\r\n",
        "  P = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(P)\r\n",
        "  P = tf.keras.layers.LeakyReLU(alpha = 0.2)(P)\r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(P)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  opt = tf.keras.optimizers.SGD(learning_rate=0.1)\r\n",
        "  model.compile(optimizer= opt, loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "pLW4ELinUefQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FC-DenseNet (Tiramisu-net)"
      ],
      "metadata": {
        "id": "8oYGI7LnBHaD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def BN_ReLU_Conv(inputs, n_filters, filter_size=3, dropout_p=0.2):\r\n",
        "    '''Apply successivly BatchNormalization, ReLu nonlinearity, Convolution and Dropout (if dropout_p > 0)''' \r\n",
        "\r\n",
        "    l = tf.keras.layers.BatchNormalization()(inputs)\r\n",
        "    l = tf.keras.layers.Activation('relu')(l)\r\n",
        "    l = tf.keras.layers.Conv2D(n_filters, filter_size, padding='same', kernel_initializer='he_uniform')(l)\r\n",
        "    if dropout_p != 0.0:\r\n",
        "        l = tf.keras.layers.Dropout(dropout_p)(l)\r\n",
        "    return l\r\n",
        "\r\n",
        "def TransitionDown(inputs, n_filters, dropout_p=0.2):\r\n",
        "    \"\"\" Apply first a BN_ReLu_conv layer with filter size = 1, and a max pooling with a factor 2  \"\"\"\r\n",
        "    l = BN_ReLU_Conv(inputs, n_filters, filter_size=1, dropout_p=dropout_p)\r\n",
        "    l = tf.keras.layers.MaxPooling2D((2,2))(l)\r\n",
        "    return l\r\n",
        "\r\n",
        "def TransitionUp(skip_connection, block_to_upsample, n_filters_keep):\r\n",
        "    '''Performs upsampling on block_to_upsample by a factor 2 and concatenates it with the skip_connection'''\r\n",
        "    #Upsample and concatenate with skip connection\r\n",
        "    l = tf.keras.layers.Conv2DTranspose(n_filters_keep, kernel_size=3, strides=2, padding='same', kernel_initializer='he_uniform')(block_to_upsample)\r\n",
        "    l = tf.keras.layers.concatenate([l, skip_connection], axis=-1)\r\n",
        "    return l\r\n",
        "\r\n",
        "def OutputLayer(inputs,n_classes):\r\n",
        "    \"\"\"\r\n",
        "    Performs 1x1 convolution followed by softmax nonlinearity\r\n",
        "    The output will have the shape (batch_size  * n_rows * n_cols, n_classes)\r\n",
        "    \"\"\"\r\n",
        "    l = tf.keras.layers.Conv2D(n_classes, kernel_size=1, padding='same', kernel_initializer='he_uniform')(inputs)\r\n",
        "#    l = Reshape((-1, n_classes))(l)\r\n",
        "    #l = Activation('sigmoid')(l)#or softmax for multi-class\r\n",
        "    return l\r\n",
        "\r\n",
        "def Tiramisu(\r\n",
        "        input_shape=(224, 224,1),\r\n",
        "        n_classes = 1,\r\n",
        "        n_filters_first_conv = 48,\r\n",
        "        n_pool = 5,\r\n",
        "        growth_rate = 16 ,\r\n",
        "        n_layers_per_block = [4,5,7,10,12,15,12,10,7,5,4],\r\n",
        "        dropout_p = 0.2\r\n",
        "        ):\r\n",
        "    if type(n_layers_per_block) == list:\r\n",
        "            print(len(n_layers_per_block))\r\n",
        "    elif type(n_layers_per_block) == int:\r\n",
        "            n_layers_per_block = [n_layers_per_block] * (2 * n_pool + 1)\r\n",
        "    else:\r\n",
        "        raise ValueError\r\n",
        "        \r\n",
        "#####################\r\n",
        "# First Convolution #\r\n",
        "#####################        \r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    stack = tf.keras.layers.Conv2D(filters=n_filters_first_conv, kernel_size=3, padding='same', kernel_initializer='he_uniform')(inputs)\r\n",
        "    n_filters = n_filters_first_conv\r\n",
        "\r\n",
        "#####################\r\n",
        "# Downsampling path #\r\n",
        "#####################     \r\n",
        "    skip_connection_list = []\r\n",
        "    \r\n",
        "    for i in range(n_pool):\r\n",
        "        for j in range(n_layers_per_block[i]):\r\n",
        "            l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\r\n",
        "            stack = tf.keras.layers.concatenate([stack, l])\r\n",
        "            n_filters += growth_rate\r\n",
        "        \r\n",
        "        skip_connection_list.append(stack)        \r\n",
        "        stack = TransitionDown(stack, n_filters, dropout_p)\r\n",
        "    skip_connection_list = skip_connection_list[::-1]\r\n",
        "\r\n",
        "    \r\n",
        "#####################\r\n",
        "#    Bottleneck     #\r\n",
        "#####################     \r\n",
        "    block_to_upsample=[]\r\n",
        "    \r\n",
        "    for j in range(n_layers_per_block[n_pool]):\r\n",
        "        l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\r\n",
        "        block_to_upsample.append(l)\r\n",
        "        stack = tf.keras.layers.concatenate([stack,l])\r\n",
        "    block_to_upsample = tf.keras.layers.concatenate(block_to_upsample)\r\n",
        "\r\n",
        "   \r\n",
        "#####################\r\n",
        "#  Upsampling path  #\r\n",
        "#####################\r\n",
        "    for i in range(n_pool):\r\n",
        "        n_filters_keep = growth_rate * n_layers_per_block[n_pool + i ]\r\n",
        "        stack = TransitionUp(skip_connection_list[i], block_to_upsample, n_filters_keep)\r\n",
        "        \r\n",
        "        block_to_upsample = []\r\n",
        "        for j in range(n_layers_per_block[ n_pool + i + 1 ]):\r\n",
        "            l = BN_ReLU_Conv(stack, growth_rate, dropout_p=dropout_p)\r\n",
        "            block_to_upsample.append(l)\r\n",
        "            stack = tf.keras.layers.concatenate([stack, l])\r\n",
        "        block_to_upsample = tf.keras.layers.concatenate(block_to_upsample)\r\n",
        "\r\n",
        "#####################\r\n",
        "#  Final         #\r\n",
        "#####################\r\n",
        "    output = OutputLayer(stack,n_classes)            \r\n",
        "    model=Model(inputs = inputs, outputs = output) \r\n",
        "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])   \r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "e4wlmTCFBFPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def scaling(xx, ss=1):\r\n",
        "            return xx * ss\r\n",
        "\r\n",
        "def FCN():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  \r\n",
        "  #Encoding\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c1 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c1 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  #c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "\r\n",
        "  c3 = tf.keras.layers.Conv2D(filters=4096, kernel_size=(7, 7), activation='relu', padding='same', dilation_rate=(2, 2), kernel_initializer='he_normal')(c3)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.5)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(filters=4096, kernel_size=(1, 1), activation='relu', padding='same',kernel_initializer='he_normal')(c3)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.5)(c3)\r\n",
        "\r\n",
        "  p1 = tf.keras.layers.Conv2D(1, kernel_size=(1, 1), activation='linear', kernel_initializer='he_normal',name='p1')(c1)\r\n",
        "  p1 = tf.keras.layers.Lambda(scaling, arguments={'ss': 1e-4})(p1)\r\n",
        "\r\n",
        "  p2 = tf.keras.layers.Conv2D(1, kernel_size=(1, 1), activation='linear', kernel_initializer='he_normal',name='p2')(c2)\r\n",
        "  p2 = tf.keras.layers.Lambda(scaling, arguments={'ss': 1e-2})(p2)\r\n",
        "\r\n",
        "  p3 = tf.keras.layers.Conv2D(1, kernel_size=(1, 1), activation='linear', kernel_initializer='he_normal',name='p3')(c3)\r\n",
        "  p3 = tf.keras.layers.Lambda(scaling, arguments={'ss': 1})(p3)\r\n",
        "\r\n",
        "  c4 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='valid', kernel_initializer='he_normal',use_bias=False)(p3)\r\n",
        "  c4 = tf.keras.layers.Add()([c4,p2])\r\n",
        "  c4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='valid', kernel_initializer='he_normal',use_bias=False)(c4)\r\n",
        "  c4 = tf.keras.layers.Add()([c4,p1])\r\n",
        "  c4 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(2, 2), strides =(2, 2), padding='valid', kernel_initializer='he_normal',use_bias=False)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2DTranspose(512, kernel_size=(2, 2), strides =(2, 2), padding='valid', kernel_initializer='he_normal',use_bias=False)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2DTranspose(512, kernel_size=(2, 2), strides =(2, 2), padding='valid', kernel_initializer='he_normal',use_bias=False)(c4)\r\n",
        "\r\n",
        "  outputs = outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c4)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "UD3DaRN7mp_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def VGGUnet_pretrained():\r\n",
        "    model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "    # Block1_conv1 weights are of the format [3, 3, 3, 64] -> this is for RGB images\r\n",
        "    # For grayscale, format should be [3, 3, 1, 64]. Weighted average of the features has to be calculated across channels.\r\n",
        "    # RGB weights: Red 0.2989, Green 0.5870, Blue 0.1140\r\n",
        "\r\n",
        "    # getting weights of block1 conv1.\r\n",
        "    block1_conv1 = model.get_layer('block1_conv1').get_weights()\r\n",
        "    weights, biases = block1_conv1\r\n",
        "\r\n",
        "    # :weights shape = [3, 3, 3, 64] - (0, 1, 2, 3)\r\n",
        "    # convert :weights shape to = [64, 3, 3, 3] - (3, 2, 0, 1)\r\n",
        "    weights = np.transpose(weights, (3, 2, 0, 1))\r\n",
        "\r\n",
        "\r\n",
        "    kernel_out_channels, kernel_in_channels, kernel_rows, kernel_columns = weights.shape\r\n",
        "\r\n",
        "    # Dimensions : [kernel_out_channels, 1 (since grayscale), kernel_rows, kernel_columns]\r\n",
        "    grayscale_weights = np.zeros((kernel_out_channels, 1, kernel_rows, kernel_columns))\r\n",
        "\r\n",
        "      # iterate out_channels number of times\r\n",
        "    for i in range(kernel_out_channels):\r\n",
        "\r\n",
        "        # get kernel for every out_channel\r\n",
        "        get_kernel = weights[i, :, :, :]\r\n",
        "\r\n",
        "        temp_kernel = np.zeros((3, 3))\r\n",
        "\r\n",
        "        # :get_kernel shape = [3, 3, 3]\r\n",
        "        # axis, dims = (0, in_channel), (1, row), (2, col)\r\n",
        "\r\n",
        "        # calculate weighted average across channel axis\r\n",
        "        in_channels, in_rows, in_columns = get_kernel.shape\r\n",
        "\r\n",
        "        for in_row in range(in_rows):\r\n",
        "            for in_col in range(in_columns):\r\n",
        "                feature_red = get_kernel[0, in_row, in_col]\r\n",
        "                feature_green = get_kernel[1, in_row, in_col]\r\n",
        "                feature_blue = get_kernel[2, in_row, in_col]\r\n",
        "\r\n",
        "            # weighted average for RGB filter\r\n",
        "            total = (feature_red * 0.2989) + (feature_green * 0.5870) + (feature_blue * 0.1140)\r\n",
        "\r\n",
        "            temp_kernel[in_row, in_col] = total\r\n",
        "\r\n",
        "\r\n",
        "        # :temp_kernel is a 3x3 matrix [rows x columns]\r\n",
        "        # add an axis at the end to specify in_channel as 1\r\n",
        "\r\n",
        "        # Second: Add axis at the start of :temp_kernel to make its shape: [1, 3, 3] which is [in_channel, rows, columns]\r\n",
        "        temp_kernel = np.expand_dims(temp_kernel, axis=0)\r\n",
        "\r\n",
        "        # Now, :temp_kernel shape is [1, 3, 3]\r\n",
        "\r\n",
        "        # Concat :temp_kernel to :grayscale_weights along axis=0\r\n",
        "        grayscale_weights[i, :, :, :] = temp_kernel\r\n",
        "\r\n",
        "      # Dimension of :grayscale_weights is [64, 1, 3, 3]\r\n",
        "      # In order to bring it to tensorflow or keras weight format, transpose :grayscale_weights\r\n",
        "\r\n",
        "      # dimension, axis of :grayscale_weights = (out_channels: 0), (in_channels: 1), (rows: 2), (columns: 3)\r\n",
        "      # tf format of weights = (rows: 0), (columns: 1), (in_channels: 2), (out_channels: 3)\r\n",
        "\r\n",
        "      # Go from (0, 1, 2, 3) to (2, 3, 1, 0)\r\n",
        "    grayscale_weights = np.transpose(grayscale_weights, (2, 3, 1, 0)) # (3, 3, 1, 64)\r\n",
        "\r\n",
        "      # combine :grayscale_weights and :biases\r\n",
        "    new_block1_conv1 = [grayscale_weights, biases]\r\n",
        "\r\n",
        "\r\n",
        "      # Reconstruct the layers of VGG16 but replace block1_conv1 weights with :grayscale_weights\r\n",
        "\r\n",
        "      # get weights of all the layers starting from 'block1_conv2'\r\n",
        "    vgg16_weights = {}\r\n",
        "    for layer in model.layers[2:]:\r\n",
        "        if \"conv\" in layer.name:\r\n",
        "            vgg16_weights[\"224_\" + layer.name] = model.get_layer(layer.name).get_weights()\r\n",
        "\r\n",
        "    del model\r\n",
        "\r\n",
        "\r\n",
        "      # Custom build VGG16\r\n",
        "    input = Input(shape=(224, 224, 1), name='224_input')\r\n",
        "      # Block 1\r\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1), data_format=\"channels_last\", name='224_block1_conv1')(input)\r\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block1_conv2')(c1)\r\n",
        "    p1 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block1_pool')(c1)\r\n",
        "\r\n",
        "      # Block 2\r\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv1')(p1)\r\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv2')(c2)\r\n",
        "    p2 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block2_pool')(c2)\r\n",
        "\r\n",
        "      # Block 3\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv1')(p2)\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv2')(c3)\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv3')(c3)\r\n",
        "    p3 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block3_pool')(c3)\r\n",
        "\r\n",
        "      # Block 4\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv1')(p3)\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv2')(c4)\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv3')(c4)\r\n",
        "    p4 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block4_pool')(c4)\r\n",
        "\r\n",
        "      # Block 5\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv1')(p4)\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv2')(c5)\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv3')(c5)\r\n",
        "    p5 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block5_pool')(c5)\r\n",
        "\r\n",
        "    base_model = Model(inputs=input, outputs=p5)\r\n",
        "\r\n",
        "    base_model.get_layer('224_block1_conv1').set_weights(new_block1_conv1)\r\n",
        "    for layer in base_model.layers[2:]:\r\n",
        "        if 'conv' in layer.name:\r\n",
        "            base_model.get_layer(layer.name).set_weights(vgg16_weights[layer.name])\r\n",
        "\r\n",
        "    x = base_model.output\r\n",
        "\r\n",
        "    for layer in base_model.layers:\r\n",
        "        layer.trainable = True\r\n",
        "\r\n",
        "    cb = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_blockb_conv1')(x)\r\n",
        "    cb = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_blockb_conv2')(cb)\r\n",
        "\r\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', name='224_block6_upsam')(cb)\r\n",
        "    u6 = tf.keras.layers.concatenate([u6, c5], name='224_block6_concat')\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv1')(u6)\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv2')(c6)\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv3')(c6)\r\n",
        "  \r\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', name='224_block7_upsam')(c6)\r\n",
        "    u7 = tf.keras.layers.concatenate([u7, c4], name='224_block7_concat')\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv1')(u7)\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv2')(c7)\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv3')(c7)\r\n",
        "\r\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name='224_block8_upsam')(c7)\r\n",
        "    u8 = tf.keras.layers.concatenate([u8, c3], name='224_block8_concat')\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv1')(u8)\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv2')(c8)\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv3')(c8)\r\n",
        "\r\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='224_block9_upsam')(c8)\r\n",
        "    u9 = tf.keras.layers.concatenate([u9, c2], name='224_block9_concat')\r\n",
        "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block9_conv1')(u9)\r\n",
        "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block9_conv2')(c9)\r\n",
        "\r\n",
        "    u10 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='224_block10_upsam')(c9)\r\n",
        "    u10 = tf.keras.layers.concatenate([u10, c1], name='224_block10_concat')\r\n",
        "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block10_conv1')(u10)\r\n",
        "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block10_conv2')(c10)\r\n",
        "      \r\n",
        "    predictions = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "    #Compilador\r\n",
        "    model = tf.keras.Model(inputs=[base_model.input], outputs=[predictions])\r\n",
        "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tDho_oUperUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def VGGSegnet():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Encoder path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "  c5 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c5)\r\n",
        "  c5 = tf.keras.layers.ReLU()(c5)\r\n",
        "  p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\r\n",
        "\r\n",
        "  #Decoder path \r\n",
        "  u1 = tf.keras.layers.UpSampling2D(size = (2, 2))(p5)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u1)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  c6 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c6)\r\n",
        "  c6 = tf.keras.layers.ReLU()(c6)\r\n",
        "  \r\n",
        "  u2 = tf.keras.layers.UpSampling2D(size = (2, 2))(c6)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u2)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "  \r\n",
        "  u3 = tf.keras.layers.UpSampling2D(size = (2, 2))(c7)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u3)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u4 = tf.keras.layers.UpSampling2D(size = (2, 2))(c8)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u4)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "\r\n",
        "  u5 = tf.keras.layers.UpSampling2D(size = (2, 2))(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u5)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  c10 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c10)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "dtZwP0KO1zct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def VGGSegnet_pretrained():\r\n",
        "    model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "    # Block1_conv1 weights are of the format [3, 3, 3, 64] -> this is for RGB images\r\n",
        "    # For grayscale, format should be [3, 3, 1, 64]. Weighted average of the features has to be calculated across channels.\r\n",
        "    # RGB weights: Red 0.2989, Green 0.5870, Blue 0.1140\r\n",
        "\r\n",
        "    # getting weights of block1 conv1.\r\n",
        "    block1_conv1 = model.get_layer('block1_conv1').get_weights()\r\n",
        "    weights, biases = block1_conv1\r\n",
        "\r\n",
        "    # :weights shape = [3, 3, 3, 64] - (0, 1, 2, 3)\r\n",
        "    # convert :weights shape to = [64, 3, 3, 3] - (3, 2, 0, 1)\r\n",
        "    weights = np.transpose(weights, (3, 2, 0, 1))\r\n",
        "\r\n",
        "\r\n",
        "    kernel_out_channels, kernel_in_channels, kernel_rows, kernel_columns = weights.shape\r\n",
        "\r\n",
        "    # Dimensions : [kernel_out_channels, 1 (since grayscale), kernel_rows, kernel_columns]\r\n",
        "    grayscale_weights = np.zeros((kernel_out_channels, 1, kernel_rows, kernel_columns))\r\n",
        "\r\n",
        "      # iterate out_channels number of times\r\n",
        "    for i in range(kernel_out_channels):\r\n",
        "\r\n",
        "        # get kernel for every out_channel\r\n",
        "        get_kernel = weights[i, :, :, :]\r\n",
        "\r\n",
        "        temp_kernel = np.zeros((3, 3))\r\n",
        "\r\n",
        "        # :get_kernel shape = [3, 3, 3]\r\n",
        "        # axis, dims = (0, in_channel), (1, row), (2, col)\r\n",
        "\r\n",
        "        # calculate weighted average across channel axis\r\n",
        "        in_channels, in_rows, in_columns = get_kernel.shape\r\n",
        "\r\n",
        "        for in_row in range(in_rows):\r\n",
        "            for in_col in range(in_columns):\r\n",
        "                feature_red = get_kernel[0, in_row, in_col]\r\n",
        "                feature_green = get_kernel[1, in_row, in_col]\r\n",
        "                feature_blue = get_kernel[2, in_row, in_col]\r\n",
        "\r\n",
        "            # weighted average for RGB filter\r\n",
        "            total = (feature_red * 0.2989) + (feature_green * 0.5870) + (feature_blue * 0.1140)\r\n",
        "\r\n",
        "            temp_kernel[in_row, in_col] = total\r\n",
        "\r\n",
        "\r\n",
        "        # :temp_kernel is a 3x3 matrix [rows x columns]\r\n",
        "        # add an axis at the end to specify in_channel as 1\r\n",
        "\r\n",
        "        # Second: Add axis at the start of :temp_kernel to make its shape: [1, 3, 3] which is [in_channel, rows, columns]\r\n",
        "        temp_kernel = np.expand_dims(temp_kernel, axis=0)\r\n",
        "\r\n",
        "        # Now, :temp_kernel shape is [1, 3, 3]\r\n",
        "\r\n",
        "        # Concat :temp_kernel to :grayscale_weights along axis=0\r\n",
        "        grayscale_weights[i, :, :, :] = temp_kernel\r\n",
        "\r\n",
        "      # Dimension of :grayscale_weights is [64, 1, 3, 3]\r\n",
        "      # In order to bring it to tensorflow or keras weight format, transpose :grayscale_weights\r\n",
        "\r\n",
        "      # dimension, axis of :grayscale_weights = (out_channels: 0), (in_channels: 1), (rows: 2), (columns: 3)\r\n",
        "      # tf format of weights = (rows: 0), (columns: 1), (in_channels: 2), (out_channels: 3)\r\n",
        "\r\n",
        "      # Go from (0, 1, 2, 3) to (2, 3, 1, 0)\r\n",
        "    grayscale_weights = np.transpose(grayscale_weights, (2, 3, 1, 0)) # (3, 3, 1, 64)\r\n",
        "\r\n",
        "      # combine :grayscale_weights and :biases\r\n",
        "    new_block1_conv1 = [grayscale_weights, biases]\r\n",
        "\r\n",
        "\r\n",
        "      # Reconstruct the layers of VGG16 but replace block1_conv1 weights with :grayscale_weights\r\n",
        "\r\n",
        "      # get weights of all the layers starting from 'block1_conv2'\r\n",
        "    vgg16_weights = {}\r\n",
        "    for layer in model.layers[2:]:\r\n",
        "        if \"conv\" in layer.name:\r\n",
        "            vgg16_weights[\"224_\" + layer.name] = model.get_layer(layer.name).get_weights()\r\n",
        "\r\n",
        "    del model\r\n",
        "\r\n",
        "\r\n",
        "      # Custom build VGG16\r\n",
        "    input = Input(shape=(224, 224, 1), name='224_input')\r\n",
        "      # Block 1\r\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1), data_format=\"channels_last\", name='224_block1_conv1')(input)\r\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block1_conv2')(c1)\r\n",
        "    p1 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block1_pool')(c1)\r\n",
        "\r\n",
        "      # Block 2\r\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv1')(p1)\r\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv2')(c2)\r\n",
        "    p2 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block2_pool')(c2)\r\n",
        "\r\n",
        "      # Block 3\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv1')(p2)\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv2')(c3)\r\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv3')(c3)\r\n",
        "    p3 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block3_pool')(c3)\r\n",
        "\r\n",
        "      # Block 4\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv1')(p3)\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv2')(c4)\r\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv3')(c4)\r\n",
        "    p4 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block4_pool')(c4)\r\n",
        "\r\n",
        "      # Block 5\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv1')(p4)\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv2')(c5)\r\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv3')(c5)\r\n",
        "    p5 = MaxPooling2D((2, 2), strides=(2, 2), name='224_block5_pool')(c5)\r\n",
        "\r\n",
        "    base_model = Model(inputs=input, outputs=p5)\r\n",
        "\r\n",
        "    base_model.get_layer('224_block1_conv1').set_weights(new_block1_conv1)\r\n",
        "    for layer in base_model.layers[2:]:\r\n",
        "        if 'conv' in layer.name:\r\n",
        "            base_model.get_layer(layer.name).set_weights(vgg16_weights[layer.name])\r\n",
        "\r\n",
        "    x = base_model.output\r\n",
        "\r\n",
        "    for layer in base_model.layers:\r\n",
        "        layer.trainable = True\r\n",
        "\r\n",
        "    cb = Conv2D(1024, (3, 3), activation='relu', padding='same', name='224_blockb_conv1')(x)\r\n",
        "    cb = Conv2D(1024, (3, 3), activation='relu', padding='same', name='224_blockb_conv2')(cb)\r\n",
        "\r\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', name='224_block6_upsam')(cb)\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv1')(u6)\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv2')(c6)\r\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block6_conv3')(c6)\r\n",
        "  \r\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', name='224_block7_upsam')(c6)\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv1')(u7)\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv2')(c7)\r\n",
        "    c7 = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block7_conv3')(c7)\r\n",
        "\r\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name='224_block8_upsam')(c7)\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv1')(u8)\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv2')(c8)\r\n",
        "    c8 = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block8_conv3')(c8)\r\n",
        "\r\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='224_block9_upsam')(c8)\r\n",
        "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block9_conv1')(u9)\r\n",
        "    c9 = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block9_conv2')(c9)\r\n",
        "\r\n",
        "    u10 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='224_block10_upsam')(c9)\r\n",
        "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block10_conv1')(u10)\r\n",
        "    c10 = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block10_conv2')(c10)\r\n",
        "      \r\n",
        "    predictions = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "    #Compilador\r\n",
        "    model = tf.keras.Model(inputs=[base_model.input], outputs=[predictions])\r\n",
        "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "C3K3SXVxO3HL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def MobielenetUnet():\r\n",
        "  inputs = Input(shape=(224, 224,1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same',strides=(2,2))(inputs)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.5)(c1)\r\n",
        "\r\n",
        "  c1 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=32,strides=(1,1),use_bias=False)(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (1, 1), kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  c1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c1)\r\n",
        "  c1 = tf.keras.layers.ReLU()(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=64,strides=(2,2),use_bias=False)(c1)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (1, 1), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  \r\n",
        "  c2 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=128,strides=(1,1),use_bias=False)(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (1, 1), kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  c2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c2)\r\n",
        "  c2 = tf.keras.layers.ReLU()(c2)\r\n",
        "\r\n",
        "  c3 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=128,strides=(2,2),use_bias=False)(c2)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (1, 1), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "\r\n",
        "  c3 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=256,strides=(1,1),use_bias=False)(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (1, 1), kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  c3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c3)\r\n",
        "  c3 = tf.keras.layers.ReLU()(c3)\r\n",
        "  \r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=256,strides=(2,2),use_bias=False)(c3)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (1, 1), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "\r\n",
        "  c4 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=512,strides=(1,1),use_bias=False)(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (1, 1), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "\r\n",
        "  c4 = tf.keras.layers.DepthwiseConv2D((3,3), padding='same',depth_multiplier=512,strides=(1,1),use_bias=False)(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (1, 1), kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  c4 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c4)\r\n",
        "  c4 = tf.keras.layers.ReLU()(c4)\r\n",
        "\r\n",
        "#Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c4)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c3])\r\n",
        "  c7 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c7 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c7)\r\n",
        "  c7 = tf.keras.layers.ReLU()(c7)\r\n",
        "\r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c2])\r\n",
        "  c8 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c8 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c8)\r\n",
        "  c8 = tf.keras.layers.ReLU()(c8)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c1])\r\n",
        "  c9 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c9 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c9)\r\n",
        "  c9 = tf.keras.layers.ReLU()(c9)\r\n",
        "  \r\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c9)\r\n",
        "  c10 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u9)\r\n",
        "  c10 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(c10)\r\n",
        "  c10 = tf.keras.layers.ReLU()(c10)  \r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "-U-ckquVNJ8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "90TnUFRZqlo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "-uoNX_0vqobS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = MobielenetUnet()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY4RQH3rq0TI",
        "outputId": "3b315164-9070-415c-aae2-c1eb0f0eca2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_name='Opa_Seg_MobilenetUnet_B4_Dataset_2'\r\n",
        "log_dir=\"logs/\"\r\n",
        "filepath = log_dir+\"Saved_models/\"+model_name+\".h5\"\r\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\r\n",
        "csv_logger = CSVLogger('logs/csv/'+model_name+'.csv', append=False, separator=';')\r\n",
        "history=model.fit(X_train, Y_train, epochs=200, batch_size=2, validation_data=(X_test, Y_test),callbacks=[csv_logger,checkpoint])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BGo7_horBNz",
        "outputId": "26aa019d-a23f-4718-a99a-78dab026c12f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "86E1QftsrSLm",
        "outputId": "5c6d21ad-04a5-4127-ad3f-78b92b375453"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\r\n",
        "plt.plot(history.history['dice_coef'])\r\n",
        "plt.plot(history.history['val_dice_coef'])\r\n",
        "plt.title('model Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "b5_35d2nrdc4",
        "outputId": "949fb69c-a1df-4e26-b713-dc6284376295"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "g=pd.read_csv('logs/csv/'+model_name+'.csv', sep=';')\r\n",
        "for i in range(len(g)):\r\n",
        "  if g['val_dice_coef'][i]==np.max(g['val_dice_coef']):\r\n",
        "    print('index =',i)\r\n",
        "    print('dice=',g['dice_coef'][i])\r\n",
        "    print('Iou=',g['iou'][i])\r\n",
        "    print('val dice=',g['val_dice_coef'][i])\r\n",
        "    print('val_Iou=',g['val_iou'][i])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqdq2QylreNG",
        "outputId": "5c019e02-76ae-41b2-92c3-d91547d53733"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "Pkr9cZi4AAdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.load_weights('logs/Saved_models/'+model_name+'.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "P__B_rhmmWTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "preds_test = model.predict(X_test)\r\n",
        "pred_img=[]\r\n",
        "for i in preds_test:\r\n",
        "  pred_img.append(np.resize(i,(224,224)))"
      ],
      "outputs": [],
      "metadata": {
        "id": "F-xBy33bK82p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.subplot(1,3,1)\r\n",
        "plt.imshow(X_test[2],cmap='gray')\r\n",
        "plt.subplot(1,3,2)\r\n",
        "plt.imshow(Y_test[2],cmap='gray')\r\n",
        "plt.subplot(1,3,3)\r\n",
        "plt.imshow(pred_img[2],cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "fKjy3sQY9sNe",
        "outputId": "890507a9-a52b-4237-cd68-1608b00508ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.subplot(1,3,1)\r\n",
        "plt.imshow(X_test[1])\r\n",
        "plt.subplot(1,3,2)\r\n",
        "plt.imshow(Y_test[1])\r\n",
        "plt.subplot(1,3,3)\r\n",
        "plt.imshow(pred_img[1])"
      ],
      "outputs": [],
      "metadata": {
        "id": "6_bH_XtYt00S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "8566dcdb-fbc8-4e47-b35f-b79e18f58e7d"
      }
    }
  ]
}